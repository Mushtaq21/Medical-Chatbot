import random
from transformers import GPTNeoForCausalLM, GPT2Tokenizer
import torch

# Load GPT-Neo model and tokenizer
model_name = "EleutherAI/gpt-neo-125M"
tokenizer = GPT2Tokenizer.from_pretrained(model_name)
model = GPTNeoForCausalLM.from_pretrained(model_name)

# Set padding token
tokenizer.pad_token = tokenizer.eos_token
model.config.pad_token_id = model.config.eos_token_id

# Predefined random topics
topics = [
    "The importance of space exploration",
    "The impact of climate change on wildlife",
    "The history of the internet",
    "How do vaccines work?",
    "The psychology behind dreams"
]

# Pick a random topic
random_topic = random.choice(topics)
print(f"Generating an article on: {random_topic}\n")

# Function to generate an article
def generate_article(prompt, max_length=300):
    inputs = tokenizer(prompt, return_tensors="pt", padding=True, truncation=True)

    outputs = model.generate(
        inputs["input_ids"],
        attention_mask=inputs["attention_mask"],
        max_length=max_length,
        num_return_sequences=1,
        no_repeat_ngram_size=2,
        top_p=0.95,
        top_k=50,
        temperature=0.7,
        do_sample=True,
        repetition_penalty=1.2,
        pad_token_id=model.config.eos_token_id
    )

    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# Generate and print the article
prompt = f"Write an informative article about {random_topic}."
article = generate_article(prompt)
print("Generated Article:\n", article)
