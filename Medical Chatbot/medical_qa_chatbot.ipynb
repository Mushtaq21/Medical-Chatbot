{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from langdetect import detect\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Dataset path\n",
        "DATASET_PATH = \"C:\\\\Users\\\\Aditya\\\\Desktop\\\\Medical Chatbot\\\\MedQuAD-master\"  //**Use your dataset path**\n",
        "CACHE_FILE = \"cached_medquad_data.csv\"\n",
        "\n",
        "@st.cache_data\n",
        "def load_medquad_cached():\n",
        "    if os.path.exists(CACHE_FILE):\n",
        "        return pd.read_csv(CACHE_FILE)\n",
        "    else:\n",
        "        df = load_medquad_from_xml(DATASET_PATH)\n",
        "        df.to_csv(CACHE_FILE, index=False)\n",
        "        return df\n",
        "\n",
        "def load_medquad_from_xml(root_folder):\n",
        "    data = []\n",
        "    for folder in os.listdir(root_folder):\n",
        "        folder_path = os.path.join(root_folder, folder)\n",
        "        if os.path.isdir(folder_path):\n",
        "            for file in os.listdir(folder_path):\n",
        "                if file.endswith(\".xml\"):\n",
        "                    file_path = os.path.join(folder_path, file)\n",
        "                    tree = ET.parse(file_path)\n",
        "                    root = tree.getroot()\n",
        "                    for qa in root.findall(\".//QAPair\"):\n",
        "                        question_elem = qa.find(\"Question\")\n",
        "                        answer_elem = qa.find(\"Answer\")\n",
        "                        question = question_elem.text.strip() if question_elem is not None and question_elem.text else None\n",
        "                        answer = answer_elem.text.strip() if answer_elem is not None and answer_elem.text else None\n",
        "                        if question and answer:\n",
        "                            data.append({\"question\": question, \"answer\": answer})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text.lower())\n",
        "    return \" \".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])\n",
        "\n",
        "@st.cache_data\n",
        "def train_retrieval_model(df):\n",
        "    vectorizer = TfidfVectorizer(preprocessor=preprocess_text)\n",
        "    tfidf_matrix = vectorizer.fit_transform(df['question'])\n",
        "    return vectorizer, tfidf_matrix\n",
        "\n",
        "def retrieve_answer(user_question, df, vectorizer, tfidf_matrix):\n",
        "    user_vector = vectorizer.transform([user_question])\n",
        "    similarities = cosine_similarity(user_vector, tfidf_matrix).flatten()\n",
        "    best_match_idx = similarities.argmax()\n",
        "    return df.iloc[best_match_idx]['answer']\n",
        "\n",
        "def detect_language(text):\n",
        "    try:\n",
        "        lang = detect(text)\n",
        "        return lang if lang in [\"hi\", \"kn\", \"mr\"] else \"en\"\n",
        "    except:\n",
        "        return \"en\"\n",
        "\n",
        "def translate_text(text, src_lang, target_lang):\n",
        "    try:\n",
        "        if src_lang == target_lang:\n",
        "            return text\n",
        "        return GoogleTranslator(source=src_lang, target=target_lang).translate(text)\n",
        "    except:\n",
        "        return text  \n",
        "\n",
        "st.set_page_config(page_title=\"Medical Q&A Chatbot\", page_icon=\"\ud83d\udcac\", layout=\"centered\")\n",
        "\n",
        "st.title(\"\ud83d\udcac Medical Q&A Chatbot\")\n",
        "st.success(\"\u2705 Loading MedQuAD dataset from cache...\")\n",
        "\n",
        "if \"qa_history\" not in st.session_state:\n",
        "    st.session_state.qa_history = []\n",
        "\n",
        "df = load_medquad_cached()\n",
        "\n",
        "if not df.empty:\n",
        "    vectorizer, tfidf_matrix = train_retrieval_model(df)\n",
        "    \n",
        "    new_question = st.text_input(\"\ud83d\udcac Ask a medical question:\", key=\"new_question_input\")\n",
        "\n",
        "    if new_question and new_question.strip() and \"first_answer\" not in st.session_state:\n",
        "        detected_lang = detect_language(new_question)\n",
        "        translated_query = translate_text(new_question, detected_lang, \"en\")\n",
        "        \n",
        "        answer = retrieve_answer(translated_query, df, vectorizer, tfidf_matrix)\n",
        "        translated_answer = translate_text(answer, \"en\", detected_lang)\n",
        "        \n",
        "        st.session_state.qa_history.append({\n",
        "            \"question\": new_question,\n",
        "            \"answer\": translated_answer\n",
        "        })\n",
        "        st.session_state.first_answer = translated_answer\n",
        "        st.rerun()\n",
        "    \n",
        "    for idx, qa in enumerate(st.session_state.qa_history):\n",
        "        st.markdown(\"\"\"---\"\"\")\n",
        "        st.subheader(f\"\ud83d\udcdd Question {idx + 1}:\")\n",
        "        st.info(qa[\"question\"])\n",
        "        \n",
        "        st.subheader(\"\ud83d\udca1 Answer:\")\n",
        "        st.success(qa[\"answer\"])\n",
        "        \n",
        "        if idx == len(st.session_state.qa_history) - 1:  # Show input only after last answer\n",
        "            followup_question = st.text_input(\"\ud83d\udcac Ask another question:\", key=f\"followup_question_{len(st.session_state.qa_history)}\")\n",
        "            \n",
        "            if followup_question and followup_question.strip():\n",
        "                detected_lang = detect_language(followup_question)\n",
        "                translated_query = translate_text(followup_question, detected_lang, \"en\")\n",
        "                \n",
        "                answer = retrieve_answer(translated_query, df, vectorizer, tfidf_matrix)\n",
        "                translated_answer = translate_text(answer, \"en\", detected_lang)\n",
        "                \n",
        "                st.session_state.qa_history.append({\n",
        "                    \"question\": followup_question,\n",
        "                    \"answer\": translated_answer\n",
        "                })\n",
        "                st.rerun()\n",
        "else:\n",
        "    st.error(\"\u274c No valid question-answer pairs found in the dataset.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}